<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Containers on Purplecarrot</title><link>https://purplecarrot.co.uk/categories/containers/</link><description>Recent content in Containers on Purplecarrot</description><generator>Hugo -- gohugo.io</generator><language>en-gb</language><lastBuildDate>Sat, 30 Oct 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://purplecarrot.co.uk/categories/containers/index.xml" rel="self" type="application/rss+xml"/><item><title>Breaking into your OpenShift Cluster</title><link>https://purplecarrot.co.uk/post/2021-10-30-breaking_into_your_openshift_cluster/</link><pubDate>Sat, 30 Oct 2021 00:00:00 +0000</pubDate><guid>https://purplecarrot.co.uk/post/2021-10-30-breaking_into_your_openshift_cluster/</guid><description>
&lt;p>Of course, this really shouldn't happen right? You're a responsible IT professional, and your OpenShift cluster is configured with multiple authentication methods, and a secure backup of a &lt;code>kubeconfig&lt;/code> file with the system:admin user certificates for passwordless login? Except sometimes it does.&lt;/p>
&lt;p>In my day job, we have a small lab OCP cluster running on vSphere that might not get used for weeks or sometimes months. The OpenShift nodes that make up the OCP cluster sometimes get automatically powered down and left off in that powered off state.&lt;/p>
&lt;p>Yesterday, I came to use this cluster for the first time again after quite a long period and found that I was unable to login with a standard LDAP user account with cluster-admin credentials that I would normally use. In addition, my admin &lt;code>kubeconfig&lt;/code> (the one generated by openshift-installer for the original installation), had very old pre-rotation CA certs or something and hadn't been used for a while. Attempting to use it just gave x509 errors and so it seemed unusable. This has happened a couple of times now over the years, and I believe it's related to it being an IPI cluster and certificate rotation issues from the cluster being powered down for long periods. Before looking at the root cause, I'm just writing down the recovery procedure I used for next time!&lt;/p>
&lt;p>So with no standard OAUTH authentication method available, I went back trying to use the original kubeconfig from the installation of the cluster.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="ln">1&lt;/span> $ export KUBECONFIG=auth/kubeconfig
&lt;span class="ln">2&lt;/span> $ oc get nodes
&lt;span class="ln">3&lt;/span> Unable to connect to the server: x509: certificate signed by unknown authority
&lt;/code>&lt;/pre>&lt;/div>&lt;p>To try and understand more about what was happening, I added &lt;code>--insecure-skip-tls-verify=true&lt;/code>, and the &lt;code>--loglevel=10&lt;/code> options to the command line, but I could see that a goroutine stack trace was immediately output after the x509 error message above.&lt;/p>
&lt;p>As any experienced senior engineer will know, the first place to go for solving any technical problem is a good Google or StackOverflow search. Unfortunately StackOverflow threw up a lot of articles that were old, or weren't quite right and not what I was looking for.&lt;/p>
&lt;p>Unsurprisingly - this being OpenShift - the best results were found in the &lt;a href="https://access.redhat.com/search/#/">RedHat Knowledgebase&lt;/a>. The KB articles &lt;a href="https://access.redhat.com/solutions/4505101">error: x509 certificate signed by unknown authority when logging in OpenShift 4 using the installation kubeconfig file&lt;/a> and &lt;a href="https://access.redhat.com/solutions/5286371">How to re create kubeconfig from scratch for system:admin user in OpenShift 4&lt;/a> looked promising, but both required existing access to the cluster to recreate them, which I didn't have because standard authentication methods were not working.&lt;/p>
&lt;p>I knew that all the certs I needed were on the cluster nodes themselves, but these systems were running RedHat CoreOS. RedHat CoreOS is based on RedHat Enterprise Linux, but designed very much as an appliance. It's not expected to be managed by a human sysadmin - it has disabled root account, doesn't allow passwordless logins and its OS configuration is managed by the MachineConfigOperator function of OpenShift. The next problem was that (for reasons of this being a lab and the cluster being built by a colleague) the SSH key for the coreos user used for the installation wasn't available to me either :-) I did however, have access to the vSphere console of these VMS. There was no option, I had break my way in and get those certs.&lt;/p>
&lt;p>The first thing was to boot the system to single user, reset the root password so I could login on the console. I've done this thousands of times over the years on many different versions of Linux and flavours of Linux, but interestingly this was more complicated on CoreOS (because of the way CoreOS works, and so it's not normally required). However, I did eventually get in and then I was able to locate the files I needed.&lt;/p>
&lt;p>So all the secrets needed to run kube-apiserver are found in &lt;code>/etc/kubenetes/static-pod-resources/kube-apiserver-certs&lt;/code>. In particular, the node-kubeconfigs/ directory has mulitple kubeconfig files, one of which was called &lt;code>lb-int.kubeconfig&lt;/code>. When I set my KUBECONFIG environment variable to point to this file, I was then able to issue oc commands to the cluster:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="ln">1&lt;/span> # cd /etc/kubenetes/static-pod-resources/kube-apiserver-certs/secrets/node-kubeconfigs
&lt;span class="ln">2&lt;/span> # export KUBECONFIG=$(pwd)/lb-int.kubeconfig
&lt;span class="ln">3&lt;/span> # oc get nodes
&lt;span class="ln">4&lt;/span> &amp;lt;lots of nodes with STATUS NotReady&amp;gt;
&lt;span class="ln">5&lt;/span> # oc get pods -A | grep -e Running
&lt;span class="ln">6&lt;/span> &amp;lt;lots of pods in ContainerCreating or Pending
&lt;span class="ln">7&lt;/span> # oc get csr -o name | xargs oc adm certificate approve
&lt;/code>&lt;/pre>&lt;/div>&lt;p>I found that half the nodes were in state &lt;code>NotReady&lt;/code>, and so the oauth-openshift containers were not &lt;code>Running&lt;/code>. This in turn was because there were a bunch of unapproved CSRs. Once these were approved, the nodes became &lt;code>Ready&lt;/code> and the OAuth authentication pods were able to start up and the cluster recovered itself in the usual way. I was then able to login normally again and recreate a backup &lt;code>kubeconfig&lt;/code>!&lt;/p></description></item><item><title>Does Alpine resolve DNS properly?</title><link>https://purplecarrot.co.uk/post/2021-09-04_does_alpine-resolve_dns_properly/</link><pubDate>Sat, 04 Sep 2021 08:51:20 +0100</pubDate><guid>https://purplecarrot.co.uk/post/2021-09-04_does_alpine-resolve_dns_properly/</guid><description>
&lt;p>To anybody who has ever used containers, Alpine is a well known base operating system layer to many popular and widely used container images in use today. By design, it's a cut down minimal OS layer using the excellent &lt;a href="https://www.busybox.net/">busybox&lt;/a> and &lt;a href="https://musl.libc.org/">musl libc&lt;/a> C library. By using these alternatives to GNU Coreutils and GNU glibc C Library, it provides a base OS container layer that allows you to build and run very small Linux containers.&lt;/p>
&lt;p>This week I was asked to look at a problem where an application team could not resolve a key DNS name used on our internal network when running their application within the container - their first thought was a problem with the OpenShift/Kubernetes environment where the container was running.&lt;/p>
&lt;p>Unfortunately, the company I work for doesn't like us to disclose internal proprietary network information, so for the purposes of the post, let's say the DNS name being queried is &lt;code>vis.company.com&lt;/code> (very important service). All IPs and some other data in the extracts below have been manually changed to private RFC1918 addresses or redacted too.&lt;/p>
&lt;h2 id="basic-troubleshooting">Basic Troubleshooting&lt;/h2>
&lt;p>The first thing to do was to perform my own DNS lookup of &lt;code>vis.company.com&lt;/code>. This worked fine from both my Linux workstation and Windows laptop.&lt;/p>
&lt;p>Now what made this problem interesting was that the application running in the container was able to resolve all other DNS entries that it was required to in order to function(eg &lt;code>a.company.com&lt;/code>, &lt;code>b.company.com&lt;/code>), but it couldn't resolve this one crucial DNS entry &lt;code>vis.company.com&lt;/code>. When you connected to a shell running inside the container and ran &lt;code>getent hosts vis.company.com&lt;/code> it simply returned nothing at all, and exited with exit code 2.&lt;/p>
&lt;h2 id="inside-the-container">Inside the Container&lt;/h2>
&lt;p>So how do you go about troubleshooting a problem like this from within a container? In a standard OS, you can simply use the standard tools in your sysadmin toolkit - ss (lsof/netstat), dig, strace, tcpdump, nmap, etc - but inside a container these are unlikely to be available by default (and some containers don't even include a minimal unix shell even). I have a pre-built container I use for situations like this that I then add as a sidecar in the pod I'm troubleshooting. Then by setting &lt;code>shareProcessNamespace: true&lt;/code> in the podspec, it will allow you to easily debug and strace processes running inside the first container from the sidecar.&lt;/p>
&lt;h2 id="dns-query">DNS Query&lt;/h2>
&lt;p>So strace'ing the DNS queries I could see the &lt;code>socket()&lt;/code> and &lt;code>bind()&lt;/code> calls, followed by receiving a response from the DNS server. However, this response was empty. Something weird was happening, because running the same command on a standard Linux host you could see 100s of lines more of system calls and a good DNS response with multiple A records was returned.&lt;/p>
&lt;p>So the next step was to use tcpdump and capture a packet trace of the DNS query. Below is the relevant section from that pcap that shows the DNS query:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="ln">1&lt;/span>18:00:27.376761 IP (tos 0x0, ttl 64, id 32569, offset 0, flags [DF], proto UDP (17), length 68)
&lt;span class="ln">2&lt;/span> 10.96.10.99.43507 &amp;gt; 10.96.0.10:domain: 19977+ A? vis.company.com. (40)
&lt;span class="ln">3&lt;/span>18:00:27.386585 IP (tos 0x0, ttl 64, id 24288, offset 0, flags [DF], proto UDP (17), length 79)
&lt;span class="ln">4&lt;/span> 10.96.0.10.domain &amp;gt; 10.96.10.99.43507: 19977| 0/0/1 (51)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>So what does this tell us?&lt;/p>
&lt;ol>
&lt;li>This is standard UDP DNS query (id 19977) to query the IPv4 record &lt;code>vis.company.com&lt;/code>&lt;/li>
&lt;li>The DNS server response comes from &lt;code>10.96.0.10&lt;/code>, which is the Kubernetes &lt;code>Service&lt;/code> address for CoreDNS.&lt;/li>
&lt;li>A DNS response was received, but no DNS records were in it (&lt;code>0/0/1&lt;/code> = 0 answer records, 0 nameservers and 1 additional record which is the query address itself)&lt;/li>
&lt;li>The &lt;code>|&lt;/code> character after the 19977 id indicates that the TC (TrunCation) bit is set on this packet.&lt;/li>
&lt;/ol>
&lt;p>The most interesting of these is the last. The TC bit is used when the DNS response the DNS server wants to send to the client is longer than the 512bytes available to it in a UDP packet (see &lt;a href="https://datatracker.ietf.org/doc/html/rfc1035">RFC1035&lt;/a> for more information.)&lt;/p>
&lt;p>This is a signal to the DNS resolver client that it needs to switch from a standard UDP DNS query and do a new TCP DNS query instead - but in both the strace and tcpdump output of the application running the the Alpine container, the resolver query exited immediate after receiving this TC UDP packet from the DNS server.&lt;/p>
&lt;p>I expected this to be a bug, but it turned out that this is a &lt;a href="https://wiki.musl-libc.org/functional-differences-from-glibc.html">functional difference between musl libc and glibc&lt;/a> and is by design. The musl libc author states that he intentionally didn't support TCP as felt it would be better for performance and UX reasons:&lt;/p>
&lt;blockquote class="twitter-tweet">&lt;p lang="en" dir="ltr">My choice not to do TCP in musl&amp;#39;s stub resolver was based on an interpretation that truncated results are not just acceptable but better ux - not only do you save major round-trip delays to DNS but you also get a reasonable upper bound on # of addrs in result.&lt;/p>&amp;mdash; Rich Felker (@RichFelker) &lt;a href="https://twitter.com/RichFelker/status/994629795551031296?ref_src=twsrc%5Etfw">May 10, 2018&lt;/a>&lt;/blockquote>
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>This is true, and a valid point. However, it means that this particular app would never work when running in a container based on Alpine. Sometimes predictable functionality is more important.&lt;/p>
&lt;p>There are various other ways this could have been made to work. Perhaps making the DNS entry smaller - which was indeed unnecessarily large - would indeed be a better fix, but unfortunately this wasn't a practical option as the DNS entry wasn't under this team's control.&lt;/p>
&lt;p>Instead, the quickest fix was to rebuild the application into a new container image using the RedHat UBI8 image as a base layer instead of Alpine. This image uses glibc resolver, and then the app then ran fine, in the same way as it did on the RedHat Linux 8 host where it had ran before being containerized.&lt;/p></description></item><item><title>Practical Tekton</title><link>https://purplecarrot.co.uk/post/2020-09-12-tekton_and_knative/</link><pubDate>Sat, 12 Sep 2020 10:11:00 +0000</pubDate><guid>https://purplecarrot.co.uk/post/2020-09-12-tekton_and_knative/</guid><description>
&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>This post gives an overview of Tekton based on my initial testing and exploration of the project within a RedHat OpenShift (Kubernetes) cluster (using v4.4 and v4.5)&lt;/p>
&lt;p>My goal was to explore the new technologies to see if I could simplify the developer experience for our developers and users. A simple task: to take a VS Code commit (running on Windows 10 desktop I used in my day job), trigger a pipeline to build the application into a container image, run unit tests and vulnerability scanning, and then deploy the application image to the OpenShift cluster using KNative.&lt;/p>
&lt;p>Note that Tekton is known as OpenShift Pipelines in OpenShift, and KNative is known as OpenShift Serverless. They're essentially the same thing, and I may use those terms interchangably in this document.&lt;/p>
&lt;p>I'm not going to cover installation of Tekton or KNative here, because there are plenty of documents out there that already cover it, both in vanilla Kubernetes clusters and OpenShift clusters. In any case with OpenShift versions of these products, it's relatively easy to install using the Operators feature found in OpenShift.&lt;/p>
&lt;h2 id="what-is-tekton">What is Tekton?&lt;/h2>
&lt;p>Tekton is a tool for creating CI/CD application container build pipelines within Kubernetes. Tekton is &lt;em>kubernetes-native&lt;/em>, meaning it was designed from the ground up as a CI/CD system running directly inside a Kubernetes cluster. It is implemented using various CRDs (&lt;code>Pipeline, PipelineRun, Tasks, ClusterTasks, Triggers, etc&lt;/code>) provided under &lt;code>tekton.dev&lt;/code> and &lt;code>triggers.tekton.dev&lt;/code> API groups. As such, if you're experienced Kubernetes user and comfortable with applying, patching and editing the YAML of Kubernetes resources, you'll be right at home.&lt;/p>
&lt;h2 id="pipelines-tasks-and-steps">Pipelines, Tasks and Steps&lt;/h2>
&lt;p>To deploy a Tekton CI/CD pipeline, you start of by creating a &lt;code>Pipeline&lt;/code> YAML resources which consists of a number of &lt;code>Tasks&lt;/code>. Each &lt;code>Task&lt;/code> in the &lt;code>Pipeline&lt;/code> gets deployed as its own pod within the namespace, and is made up of a series of steps, which each step being a separate container image in the pod.&lt;/p>
&lt;p>So, for example if you have a &lt;code>Task&lt;/code> with three build, push, scan steps, a single pod with three different container images is normally deployed. In addition, Tekton itself adds init containers and other things to the pod in order to execute the pipeline (for example, the pipelines-creds-init-rhel8 init container which setups secrets and any script resources specified in your tasks, etc). The order of execution of each &lt;code>Task&lt;/code> is determined by setting the &lt;code>spec.tasks[*].runAfter:&lt;/code> parameter, which can be used to ensure the Pipeline runs in a specific order (steps can also run in parallel by setting these to be the same on different &lt;code>Tasks&lt;/code>). Below is a fabricated example to illustrate this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="ln"> 1&lt;/span>&lt;span class="nt">apiVersion&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">tekton.dev/v1beta1&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 2&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Pipeline&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 3&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">metadata&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 4&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">my-pipeline&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 5&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">spec&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 6&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">tasks&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 7&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">git-clone&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 8&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">taskRef&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 9&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Task&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">10&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">git-clone&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">11&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">build&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">12&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">taskRef&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">13&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Task&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">14&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">build&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">15&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">runAfter&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">16&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="l">git-clone&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">17&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">scan&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">18&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">taskRef&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">19&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Task&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">20&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">scan&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">21&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">runAfter&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">22&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="l">build&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">23&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">push&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">24&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">taskRef&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">25&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Task&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">26&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">push&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">27&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">runAfter&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">28&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="l">scan&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="ln"> 1&lt;/span>&lt;span class="nt">apiVersion&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">tekton.dev/v1beta1&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 2&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Task&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 3&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">metadata&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 4&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">build&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 5&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">spec&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 6&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">steps&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 7&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">build-binary&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 8&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">image&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">registry/builder:latest&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 9&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">test&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">10&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">image&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">registry/test:latest&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Tekton has a &lt;a href="https://github.com/tektoncd/catalog">catalog&lt;/a> of pre-created &lt;code>Tasks&lt;/code>, and RedHat have a curated list of these that are then bundled as ClusterTasks and installed when OpenShift Pipelines is. &lt;code>ClusterTasks&lt;/code> are identical to &lt;code>Tasks&lt;/code> except that they are global resources and available for use by all users across all namespaces in a cluster, whereas &lt;code>Tasks&lt;/code> are namespaced.&lt;/p>
&lt;h2 id="parameters">Parameters&lt;/h2>
&lt;p>Inputs to your pipeline are specified in &lt;code>spec.params&lt;/code> of the &lt;code>Pipeline&lt;/code> object, and these can then be made available to and referenced by each task (&lt;code>spec.tasks[*].params&lt;/code>):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="ln"> 1&lt;/span>&lt;span class="nt">apiVersion&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">tekton.dev/v1beta1&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 2&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Pipeline&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 3&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">metadata&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 4&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">my-pipeline&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 5&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">spec&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 6&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">params&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 7&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">GIT_REPO&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 8&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">string&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 9&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">description&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">URL of the Git repository&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">10&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">GIT_BRANCH&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">11&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">string&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">12&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">description&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Git Branch&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">13&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">REGISTRY&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">14&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">string&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">15&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">description&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Container registry name&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">16&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">DEST_IMAGE&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">17&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">string&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">18&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">description&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Name of image that will be built&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">19&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">DEST_IMAGE_TAG&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">20&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">string&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">21&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">description&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Image tag&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">22&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">tasks&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">23&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">git-clone&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">24&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">taskRef&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">25&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Task&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">26&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">git-clone&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">27&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">params&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">28&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">source_dir&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">29&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">value&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s2">&amp;#34;$(params.GIT_REPO)&amp;#34;&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">30&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">build&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">31&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">taskRef&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">32&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Task&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">33&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">build&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">34&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">params&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">35&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">image-name&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">36&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">value&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">&amp;#34;$(params.REGISTRY)/${DEST_IMAGE}/${DEST_IMAGE_TAG}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can also use parameters that were the outputs from other &lt;code>Tasks&lt;/code> that have already executed. For example, you could use the Git commit SHA from the HEAD of the repository you clone in a git-clone &lt;code>Task&lt;/code>, and pass it as an input into the build &lt;code>Task&lt;/code> that builds the container (for example, perhaps you want to add a container image LABEL with the commit sha). These are held in a parameter called &lt;code>$(tasks.&amp;lt;task_name&amp;gt;.results)&lt;/code> (tou can also create these yourself, more on that in a different post)&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="ln"> 1&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">tasks&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 2&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">git-clone&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 3&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">taskRef&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 4&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Task&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 5&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">git-clone&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 6&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">build&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 7&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">taskRef&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 8&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Task&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 9&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">build&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">10&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">params&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">11&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">commit&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">12&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">value&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s2">&amp;#34;$(tasks.git-clone.results.commit)&amp;#34;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="pipelineresources">PipelineResources&lt;/h2>
&lt;p>There is also a Tekton resource type called a &lt;code>PipelineResource&lt;/code>, which is an input or output object that can be defined as a &lt;code>spec.resource&lt;/code> and provided to a &lt;code>Task&lt;/code>. For example, you might have a Git Repo &lt;code>PipelineResource&lt;/code> input which defines a Git repo (url, branch) a Git clone type &lt;code>Task&lt;/code> can use as an input, or an output object for a container image output from a build &lt;code>Tasks&lt;/code> (eg &lt;code>$(resources.outputs.image.url)&lt;/code>).&lt;/p>
&lt;p>In my experience with Tekton 0.7, these were hideously complicated to debug, I found them very opaque and hard to troubleshoot, and had compatability issues using them where they didn't fully support the auth mechanism of our container registry (JFrog Artifactory). In most cases using parameters was easier and just as functional, so I quickly stopped using PipelineResources.&lt;/p>
&lt;p>In additon, during OpenShift Pipelines version updates I noticed that more ClusterTasks were switching from using PipelineResouurces as inputs to using standard parameters as inputs (eg &lt;code>$(params.git_url&lt;/code>) instead of &lt;code>$(resources.inputs.git.url)&lt;/code>). There is a section of the Tetkon docs &lt;a href="https://github.com/tektoncd/pipeline/blob/master/docs/resources.md#why-arent-pipelineresources-in-beta">Why Aren't PipelineResources in Beta?&lt;/a> which also suggests there have been issues, and so it appears that they are falling out of favour or at least need some more work. In any case, I've not found a compelling reason for using them over parameters.&lt;/p>
&lt;h2 id="secrets">Secrets&lt;/h2>
&lt;p>When using &lt;code>Secrets&lt;/code> with Tekton it is worth noting that in comparison to others users of &lt;code>Secrets&lt;/code>. Tekton is very particular about their type and annotations. Most of our &amp;quot;Git secrets&amp;quot; (&lt;code>Secrets&lt;/code> containing private SSH keys that are attached to &lt;code>BuildConfigs&lt;/code>) were initially created as &lt;code>type: Opaque&lt;/code>. Whilst this allows them to be used with &lt;code>BuildConfigs&lt;/code>, they are not picked up and used with Tekton. To use them, you will need to ensure the &lt;code>Secrets&lt;/code> type is set to &lt;code>type: kubernetes.io/ssh-auth&lt;/code>.&lt;/p>
&lt;p>In addition, Tekton secrets must have annotations that explictly define hosts where they will be used. Lastly, a &lt;code>data.known_hosts&lt;/code> (which you can get from $HOME/.ssh/know_hosts after you've connected to it via SSH) is also required to avoid error messages. The example below shows an example of a correctly annotated SSH key &lt;code>Secret&lt;/code> for use with Tekton.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="ln"> 1&lt;/span>&lt;span class="nt">apiVersion&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">v1&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 2&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Secret&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 3&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">metadata&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 4&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">my_git_ssh_key&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 5&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">annotations&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 6&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">tekton.dev/git-0&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">mygithost.example.com &lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 7&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">kubernetes.io/ssh-auth&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 8&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">data&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln"> 9&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">ssh-privatekey&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">&amp;lt;base64 encoded&amp;gt;&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="ln">10&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">known_hosts&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">&amp;lt;base64 encoded&amp;gt;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="workspaces">Workspaces&lt;/h2>
&lt;p>Workspaces were introduced into Tekton as a new feature whilst I was working on it. They're kind of like standard &lt;code>Volumes&lt;/code> in a Pod in that they present &lt;code>Secrets&lt;/code>, &lt;code>ConfigMaps&lt;/code> or &lt;code>PersistentVolumeClaims&lt;/code> into a location in the filesystem of a given &lt;code>Task's&lt;/code> pod. I only used a &lt;code>PVC&lt;/code> in my testing. The value of this is that you can share data between tasks (eg the source code your application build task needs after it has cloned from your git clone task).&lt;/p>
&lt;h2 id="running-a-pipeline">Running a Pipeline&lt;/h2>
&lt;p>When you execute a &lt;code>Pipeline&lt;/code> a &lt;code>PipelineRun&lt;/code> object is created that connects the &lt;code>Workspace&lt;/code>, &lt;code>ServiceAccounts&lt;/code>, &lt;code>Pipelines&lt;/code> etc together and deploys the Pods needed to run your &lt;code>Pipeline&lt;/code> - or in other words, there is one &lt;code>PipelineRun&lt;/code> object created for each time the &lt;code>Pipeline&lt;/code> is executed.&lt;/p>
&lt;p>As all Tekton objects are implemented natively in Kubernetes as CRDs, you could just use oc/kubectl to use Tekton, but using tkn CLI client is much easier (in OpenShift, you can also use the Web Console UI, navigate Pipelines menu then simply click Start in the context menu) for interacting and using Tekton pipelines. For example, to start your pipeline run the following command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="ln">1&lt;/span>tkn start mypipeline
&lt;/code>&lt;/pre>&lt;/div>&lt;p>By default, tkn will go into an interactive mode and prompt you to enter all the input information it requires. But I quickly got into the habit of passing these all as additional command line parameters, and immediately displaying any logs.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="ln">1&lt;/span>tkn pipeline start mypipeline --user-param-defaults -w name=workspace,claimName=workspace --showlog
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>Though I have been using OpenShift and Kubernetes for quite a few years, I was new to both KNative and Tekton. Both are fast moving projects, with many resources in alpha or beta (RedHat Tech Preview) at best.&lt;/p>
&lt;p>As with any new software, it can be a little tricky to workout and understand how it all integrates together. This is particulary true in a company like the one where I work where we run OpenShift/Kubernetes clusters in a more secure, disconnected, on-premise environment.&lt;/p>
&lt;p>In particular, we tend to run with on-prem instances of commercial products (eg JFrog Artifactory Container Registry) instead of cloud or externally hosted service (like Docker Hub or Quay.io). Even though these services run on a private disconnected network, we are also required to adhere to stricter security policies than most organisations (eg never public open access Git repos or registries, always requiring credentials for any type of pull or push, using private CAs and PKI). This means being an early adopter of new software- that developers and testers have developed with standard cloud services out on the internet rather than on-prem commerical products - you're likely to encounter more bugs for the first time using new projects.&lt;/p>
&lt;p>The table below shows the versions I've been using, and each version fixed bugs I'd actually seen myself in the prior version. I can't stress enough that if you're an OpenShift or non-cloud Kubernetes user where you manage the versions, use both the latest OpenShift and Pipeline versions.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>OpenShift&lt;/th>
&lt;th>Pipelines&lt;/th>
&lt;th>Base Tekton&lt;/th>
&lt;th>tkn CLI&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>OpenShift 4.6&lt;/td>
&lt;td>Tech Preview 1.2&lt;/td>
&lt;td>Tekton 0.16.3&lt;/td>
&lt;td>tkn 0.13.1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>OpenShift 4.5&lt;/td>
&lt;td>Tech Preview 1.1&lt;/td>
&lt;td>Tekton 0.14.3&lt;/td>
&lt;td>tkn 0.11.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>OpenShift 4.4&lt;/td>
&lt;td>Tech Preview 1.0&lt;/td>
&lt;td>Tekton 0.11.3&lt;/td>
&lt;td>tkn 0.9.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>The other thing with new alpha/beta software is that it changes quite quickly, and this means that many of the articles, tutorials, GitHub comments and issues reference objects that have been deprecated or now have a new &lt;code>spec:&lt;/code> or something (for example one of the prominent Serverless tutorials still in the top of Google searchs as I write this even details the KNative build component, which has now been deprecated in favour of Tekton in a separate project). Be very careful using older examples and tutorials found on the internet.&lt;/p>
&lt;p>Anyway, after a few teething issues I got a working Python pipeline where I built, scanned and deployed a Python container image as a Knative service and I can say I really like Tekton. In particular, I never really enjoyed writing Groovy and much prefer creating pipelines from combination of bash scripts and YAML editing of Kubernetes resources.&lt;/p>
&lt;p>In my next post, I will detail how I'm using KNative (Serverless) as a lightweight way to deploy your application at the end of the Pipeline. Knative promises lots, but its use in development and build systems is a solid use case that can easily be used today.&lt;/p></description></item></channel></rss>